{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzobalzani/nlp_projects/blob/master/Assignment1/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP - Assignment 1\n",
        "\n",
        "Lorenzo Balzani, Alessia Deana, Thomas Guizzetti\n",
        "\n",
        "lorenzo.balzani@studio.unibo.it, alessia.deana@studio.unibo.it, thomas.guizzetti@studio.unibo.it"
      ],
      "metadata": {
        "id": "ZZIsVV1UPpPQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WeCeITXoxLf"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "**Credits**: Federico Ruggeri, Eleonora Mancini, Paolo Torroni\n",
        "\n",
        "**Keywords**: POS tagging, Sequence labelling, RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjkxhBP7lXWN"
      },
      "source": [
        "\n",
        "# Contact\n",
        "\n",
        "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "* Eleonora Mancini -> e.mancini@unibo.it\n",
        "\n",
        "Professor:\n",
        "\n",
        "* Paolo Torroni -> p.torroni@unibo.it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH8iQ2uOlXWQ"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "You are tasked to address the task of POS tagging.\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://github.com/lorenzobalzani/nlp_assigments/blob/master/Assignment1/images/pos_tagging.png?raw=1\" alt=\"POS tagging\" />\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FlqdA_wlXWR"
      },
      "source": [
        "# [Task 1 - 0.5 points] Corpus\n",
        "\n",
        "You are going to work with the [Penn TreeBank corpus](https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip).\n",
        "\n",
        "**Ignore** the numeric value in the third column, use **only** the words/symbols and their POS label.\n",
        "\n",
        "### Example\n",
        "\n",
        "```Pierre\tNNP\t2\n",
        "Vinken\tNNP\t8\n",
        ",\t,\t2\n",
        "61\tCD\t5\n",
        "years\tNNS\t6\n",
        "old\tJJ\t2\n",
        ",\t,\t2\n",
        "will\tMD\t0\n",
        "join\tVB\t8\n",
        "the\tDT\t11\n",
        "board\tNN\t9\n",
        "as\tIN\t9\n",
        "a\tDT\t15\n",
        "nonexecutive\tJJ\t15\n",
        "director\tNN\t12\n",
        "Nov.\tNNP\t9\n",
        "29\tCD\t16\n",
        ".\t.\t8\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv6l58L7lXWU"
      },
      "source": [
        "### Splits\n",
        "\n",
        "The corpus contains 200 documents.\n",
        "\n",
        "   * **Train**: Documents 1-100\n",
        "   * **Validation**: Documents 101-150\n",
        "   * **Test**: Documents 151-199"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87gikb4ZlXWV"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* **Download** the corpus.\n",
        "* **Encode** the corpus into a pandas.DataFrame object.\n",
        "* **Split** it in training, validation, and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "OhjWc5uHlXWX",
        "ExecuteTime": {
          "end_time": "2023-11-25T10:56:28.029689Z",
          "start_time": "2023-11-25T10:55:58.591549Z"
        }
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install wget gensim prettytable\n",
        "%pip install cudf-cu11 --extra-index-url=https://pypi.nvidia.com\n",
        "%pip install gdown==4.6.0\n",
        "\n",
        "\n",
        "import os\n",
        "import wget\n",
        "from zipfile import ZipFile\n",
        "from typing import List, Dict, Tuple, Any\n",
        "import hashlib\n",
        "from prettytable import PrettyTable\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score, classification_report, precision_score, recall_score\n",
        "from collections import Counter\n",
        "import gensim\n",
        "import gensim.downloader as gensim_downloader\n",
        "from google.colab import drive\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import gdown\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAzsHjT8lXWe",
        "outputId": "cd281f85-0d3b-4ffe-8875-ce3f9c5d387e",
        "scrolled": true,
        "ExecuteTime": {
          "end_time": "2023-11-25T10:56:33.152226Z",
          "start_time": "2023-11-25T10:56:32.688132Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check on training set: True\n",
            "Check on validation set: True\n",
            "Check on validation set: True\n"
          ]
        }
      ],
      "source": [
        "def create_dataframe_and_split(download_dataset: bool = False, folder_path: str = \"dependency_treebank\") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    dataframe: List[Dict[str, str]] = list()\n",
        "    dataset_filename: str = f\"{folder_path}.zip\"\n",
        "    if download_dataset and not os.path.exists(dataset_filename):\n",
        "      wget.download(\"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\")\n",
        "      with ZipFile(dataset_filename, \"r\") as zObject:\n",
        "        zObject.extractall()\n",
        "\n",
        "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
        "        dp_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.dp')])\n",
        "\n",
        "        for dp_file in dp_files:\n",
        "            with open(os.path.join(folder_path, dp_file), 'r') as file:\n",
        "                for line in file.readlines():\n",
        "                    line = line.split(\"\\t\")[:-1]\n",
        "                    if len(line) > 0: # some lines can be empty\n",
        "                        dataframe.append({\"value\": line[0], \"pos_label\": line[1], \"doc_idx\": int(dp_file.split(\"_\")[-1].split(\".\")[0])})\n",
        "\n",
        "    else:\n",
        "        print(\"The specified folder does not exist or is not a directory.\")\n",
        "    df: pd.DataFrame = pd.DataFrame.from_dict(dataframe)\n",
        "    train: pd.DataFrame = df[df[\"doc_idx\"] <= 100]\n",
        "    validation: pd.DataFrame = df[(df[\"doc_idx\"] > 100) & (df[\"doc_idx\"] <= 150)]\n",
        "    test: pd.DataFrame = df[(df[\"doc_idx\"] > 150) & (df[\"doc_idx\"] <= 199)]\n",
        "    return train, validation, test\n",
        "\n",
        "train, validation, test = create_dataframe_and_split(download_dataset = True)\n",
        "\n",
        "# Test\n",
        "print(f\"Check on training set:\", all(train[\"doc_idx\"] <= 100))\n",
        "print(f\"Check on validation set:\", all((validation[\"doc_idx\"] > 100) & (validation[\"doc_idx\"] <= 150)))\n",
        "print(f\"Check on validation set:\", all((test[\"doc_idx\"] > 150) & (test[\"doc_idx\"] <= 199)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGybUWhzlXWi"
      },
      "source": [
        "# [Task 2 - 0.5 points] Text encoding\n",
        "\n",
        "To train a neural POS tagger, you first need to encode text into numerical format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPIBr6_flXWk"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "* Embed words using **GloVe embeddings**.\n",
        "* You are **free** to pick any embedding dimension.\n",
        "* [Optional] You are free to experiment with text pre-processing: **make sure you do not delete any token!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m2xFbs1vqWZ0",
        "ExecuteTime": {
          "end_time": "2023-11-25T11:17:22.823060Z",
          "start_time": "2023-11-25T11:17:22.793773Z"
        }
      },
      "outputs": [],
      "source": [
        "def load_embedding_model(model_type: str, embedding_dimension: int = 50) -> gensim.models.keyedvectors.KeyedVectors:\n",
        "    \"\"\"\n",
        "    Loads a pre-trained word embedding model via gensim library.\n",
        "\n",
        "    :param model_type: name of the word embedding model to load.\n",
        "    :param embedding_dimension: size of the embedding space to consider\n",
        "\n",
        "    :return\n",
        "        - pre-trained word embedding model (gensim KeyedVectors object)\n",
        "    \"\"\"\n",
        "    download_path = \"\"\n",
        "    if model_type.strip().lower() == 'word2vec':\n",
        "        download_path = \"word2vec-google-news-300\"\n",
        "\n",
        "    elif model_type.strip().lower() == 'glove':\n",
        "        download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n",
        "    elif model_type.strip().lower() == 'fasttext':\n",
        "        download_path = \"fasttext-wiki-news-subwords-300\"\n",
        "    else:\n",
        "        raise AttributeError(\"Unsupported embedding model type! Available ones: word2vec, glove, fasttext\")\n",
        "\n",
        "    try:\n",
        "        emb_model = gensim_downloader.load(download_path)\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid embedding model name! Check the embedding dimension:\")\n",
        "        print(\"Word2Vec: 300\")\n",
        "        print(\"Glove: 50, 100, 200, 300\")\n",
        "        print('FastText: 300')\n",
        "        raise e\n",
        "\n",
        "    return emb_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 300\n",
        "model_type = \"glove\"\n",
        "embedding_filename = f\"{model_type}_{embedding_dim}_embeddings.pt\"\n",
        "\n",
        "try:\n",
        "  print(f\"Attempting to download {embedding_filename} from Drive...\")\n",
        "  file_id = '1CnoH7tB-1v-1J_Qf2WVelew6wY7RTOd7'\n",
        "  url = f'https://drive.google.com/uc?id={file_id}'\n",
        "  gdown.download(url, embedding_filename, quiet=False)\n",
        "  embedding_model = torch.load(embedding_filename)\n",
        "  print(f\"Successfully downloaded {embedding_filename} from Drive!\")\n",
        "except: # Load and save the model if it doesn't exist\n",
        "    print(\"Loading embedding model...\")\n",
        "    embedding_model = load_embedding_model(model_type=model_type, embedding_dimension=embedding_dim)\n",
        "    torch.save(embedding_model, embedding_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8caBIJDda_v",
        "outputId": "e781376a-ea35-4169-9fae-0fa004415dca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to download glove_300_embeddings.pt from Drive...\n",
            "Access denied with the following error:\n",
            "Loading embedding model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1CnoH7tB-1v-1J_Qf2WVelew6wY7RTOd7 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check OOV words"
      ],
      "metadata": {
        "id": "t7oj_0pc1kRv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Y8fpybUhtWTK",
        "ExecuteTime": {
          "end_time": "2023-11-25T10:58:31.240815Z",
          "start_time": "2023-11-25T10:58:31.019864Z"
        }
      },
      "outputs": [],
      "source": [
        "def check_oov_terms(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
        "                    word_listing: List[str]):\n",
        "    \"\"\"\n",
        "    Checks differences between pre-trained embedding model vocabulary\n",
        "    and dataset specific vocabulary in order to highlight out-of-vocabulary terms.\n",
        "\n",
        "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "    :param word_listing: dataset specific vocabulary (list)\n",
        "\n",
        "    :return\n",
        "        - list of OOV terms\n",
        "    \"\"\"\n",
        "    embedding_vocabulary = set(embedding_model.key_to_index.keys())\n",
        "    oov = set(word_listing).difference(embedding_vocabulary)\n",
        "    return list(oov)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### No pre-processing"
      ],
      "metadata": {
        "id": "Pru-Hweq1yO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oov_terms = check_oov_terms(embedding_model, train['value'].unique())\n",
        "oov_percentage = float(len(oov_terms)) / len(train['value'].unique())\n",
        "print(f\"Total OOV terms in the train set: {len(oov_terms)} ({oov_percentage:.2%})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqK8rleB1gRY",
        "outputId": "20bee145-92ad-4cc8-f80f-df0ffcfdbbe0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total OOV terms in the train set: 2346 (29.29%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Applying lower()"
      ],
      "metadata": {
        "id": "AlobewFE12z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['value'] = train['value'].str.lower()\n",
        "validation['value'] = validation['value'].str.lower()\n",
        "test['value'] = test['value'].str.lower()\n",
        "oov_terms_lowercase = check_oov_terms(embedding_model, train['value'])\n",
        "oov_terms_lowercase_percentage = float(len(oov_terms_lowercase)) / len(train['value'].unique())\n",
        "print(f\"Total OOV terms in the train set after applying lowercase method: {len(oov_terms_lowercase)} ({oov_terms_lowercase_percentage:.2%})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHj43ZSP1cix",
        "outputId": "ef579210-45f2-49c1-9a63-816dd55e7cef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total OOV terms in the train set after applying lowercase method: 359 (4.85%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lemmatization"
      ],
      "metadata": {
        "id": "3MIyLHrr1-Qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def convert_pos_tags(pos_tag: str) -> str:\n",
        "    mapping = {\n",
        "        \"CC\": wordnet.NOUN,\n",
        "        \"CD\": wordnet.NOUN,\n",
        "        \"DT\": wordnet.NOUN,\n",
        "        \"EX\": wordnet.NOUN,\n",
        "        \"FW\": wordnet.NOUN,\n",
        "        \"IN\": wordnet.NOUN,\n",
        "        \"JJ\": wordnet.ADJ,\n",
        "        \"JJR\": wordnet.ADJ,\n",
        "        \"JJS\": wordnet.ADJ,\n",
        "        \"LS\": wordnet.NOUN,\n",
        "        \"MD\": wordnet.VERB,\n",
        "        \"NN\": wordnet.NOUN,\n",
        "        \"NNS\": wordnet.NOUN,\n",
        "        \"NNP\": wordnet.NOUN,\n",
        "        \"NNPS\": wordnet.NOUN,\n",
        "        \"PDT\": wordnet.ADJ,\n",
        "        \"POS\": wordnet.NOUN,\n",
        "        \"PRP\": wordnet.NOUN,\n",
        "        \"PRP$\": wordnet.NOUN,\n",
        "        \"RB\": wordnet.ADV,\n",
        "        \"RBR\": wordnet.ADV,\n",
        "        \"RBS\": wordnet.ADV,\n",
        "        \"RP\": wordnet.NOUN,\n",
        "        \"SYM\": wordnet.NOUN,\n",
        "        \"TO\": wordnet.NOUN,\n",
        "        \"UH\": wordnet.NOUN,\n",
        "        \"VB\": wordnet.VERB,\n",
        "        \"VBD\": wordnet.VERB,\n",
        "        \"VBG\": wordnet.VERB,\n",
        "        \"VBN\": wordnet.VERB,\n",
        "        \"VBP\": wordnet.VERB,\n",
        "        \"VBZ\": wordnet.VERB,\n",
        "        \"WDT\": wordnet.NOUN,\n",
        "        \"WP\": wordnet.NOUN,\n",
        "        \"WP$\": wordnet.NOUN,\n",
        "        \"WRB\": wordnet.ADV\n",
        "    }\n",
        "\n",
        "    return mapping.get(pos_tag)\n",
        "\n",
        "\n",
        "def lemmatize_dataset(word: str, pos_label: str = None) -> str:\n",
        "    try:\n",
        "      lemma: str = lemmatizer.lemmatize(word, convert_pos_tags(pos_label))\n",
        "      return lemma\n",
        "    except Exception as e:\n",
        "      return word\n",
        "\n",
        "train_lemmatize = train.copy(deep=True)\n",
        "validation_lemmatize = train.copy(deep=True)\n",
        "test_lemmatize = train.copy(deep=True)\n",
        "\n",
        "train_lemmatize['value'] = train_lemmatize.apply(lambda row: lemmatize_dataset(row['value'], row['pos_label']), axis=1)\n",
        "validation_lemmatize['value'] = validation_lemmatize.apply(lambda row: lemmatize_dataset(row['value']), axis=1)\n",
        "test_lemmatize['value'] = test_lemmatize.apply(lambda row: lemmatize_dataset(row['value']), axis=1)\n",
        "\n",
        "oov_terms_lemmatization = check_oov_terms(embedding_model, train_lemmatize['value'].unique())\n",
        "oov_percentage_lemmatization = float(len(oov_terms_lemmatization)) / len(train_lemmatize['value'].unique())\n",
        "print(f\"Total OOV terms in the train set: {len(oov_terms_lemmatization)} ({oov_percentage_lemmatization:.2%})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odxx8_Isqzwy",
        "outputId": "bfd81735-beba-4875-9570-6fe29f549eef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total OOV terms in the train set: 363 (6.00%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatizing words in a pre-processing pipeline for extracting Part-of-Speech (POS) tags may not always be beneficial and can inadvertently lead to an increase in out-of-vocabulary (OOV) instances. Lemmatization involves reducing words to their base or root form which could not be beneficial when aiming to extract POS tags, since preserving the original word forms may be more advantageous. This transformation can introduce ambiguity and misclassification, especially caused by the loss of distinct syntactic information crucial for accurate POS tagging."
      ],
      "metadata": {
        "id": "Qt6a_RjAmtnD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We notive that uppercase/capitalized words are for the most part not present in the Glove embedding. After some experimentation, we realised that applying a `lower()` method to the dataset increases the number of unique embeddings in our models, resulting in an higher f1-score. Furthermore, we also notice more words not present in the Glove embedding of type as below:\n",
        "\n",
        "* Numerical Values and Quantities: These are numbers often used in financial, scientific, or statist`cal contexts. They can be whole numbers, decimals, or even fractions. Examples include '1.457', '100,980', '12,252', and '1\\/10th'.\n",
        "\n",
        "* Alphanumeric Combinations: These are words that combine numbers and letters, often used in specific technical or branded contexts. Examples include 'c-90', 'c.j.b.', and 'ctbs'.\n",
        "\n",
        "* Composite Words or Compound Words: These are words formed by combining two or more words, often linked by hyphens. They are used to create a specific or more nuanced meaning than the individual words alone. Examples include 'asset-sale', 'auto-safety', 'beer-belly', 'capital-gains', 'computer-system-design', and 'family-planning'.\n",
        "\n",
        "* Bracket Representations: Words like '-lcb-', '-lrb-', '-rcb-', and '-rrb-' are likely placeholders or encoded representations for left and right brackets (curly and round), often used in text processing or encoding.\n",
        "\n",
        "* Branded or Specific Names: These include names that might be specific to companies, brands, models, or even specific terms within an industry. Examples include 'bridgestone/firestone', 'corton-charlemagne', 'akerfeldt', and 'aslacton'.\n",
        "\n",
        "* Mixture of Alphabetic and Symbolic Characters: Some entries combine letters with symbols, such as 'creator's' and 'delwin'. These may represent possessive forms or be specific names or terms with an apostrophe.\n",
        "\n",
        "* Hyphenated Descriptive Terms: These are descriptive phrases often hyphenated to express a specific idea or concept, like 'big-ticket', 'bald-faced', and 'dead-eyed'.\n",
        "\n",
        "* Technical or Industry-Specific Terms: Some words seem to be specific to certain fields or industries, like 'crocidolite' (a type of asbestos), 'amphobiles', and 'antitrust-law'."
      ],
      "metadata": {
        "id": "dVsRGNj0tJzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set(oov_terms_lowercase) - set(oov_terms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCt3fY-GrcTn",
        "outputId": "b775b525-9c49-4742-cf88-ef285fffd256"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'-lcb-',\n",
              " '-lrb-',\n",
              " '-rcb-',\n",
              " '-rrb-',\n",
              " 'ac-130u',\n",
              " 'akerfeldt',\n",
              " 'alurralde',\n",
              " 'anti-china',\n",
              " 'ariail',\n",
              " 'aslacton',\n",
              " 'bermuda-based',\n",
              " 'biondi-santi',\n",
              " 'boorse',\n",
              " 'bridgestone\\\\/firestone',\n",
              " 'bumkins',\n",
              " 'c-90',\n",
              " 'c.j.b.',\n",
              " 'centerbank',\n",
              " 'chafic',\n",
              " 'chemplus',\n",
              " 'chilver',\n",
              " 'chinchon',\n",
              " 'chong-sik',\n",
              " 'coche-dury',\n",
              " 'colonsville',\n",
              " 'corton-charlemagne',\n",
              " 'cotran',\n",
              " 'cray-3',\n",
              " \"creator's\",\n",
              " 'ctbs',\n",
              " 'delwin',\n",
              " 'deposits-a',\n",
              " 'derel',\n",
              " 'dollar-yen',\n",
              " 'drobnick',\n",
              " 'ensrud',\n",
              " 'erbamont',\n",
              " 'ft-se',\n",
              " 'ghkm',\n",
              " 'gingl',\n",
              " 'glenham',\n",
              " 'hallwood',\n",
              " 'hummerstone',\n",
              " 'ingersoll-rand',\n",
              " 'integra-a',\n",
              " 'iran\\\\/contra',\n",
              " 'jalaalwalikraam',\n",
              " 'jerritts',\n",
              " 'kalipharma',\n",
              " 'lafite-rothschild',\n",
              " 'landonne',\n",
              " 'lezovich',\n",
              " 'macheski',\n",
              " 'macmillan\\\\/mcgraw',\n",
              " 'macmillan\\\\/mcgraw-hill',\n",
              " 'makato',\n",
              " 'malizia',\n",
              " 'mehrens',\n",
              " 'meinders',\n",
              " 'micronite',\n",
              " 'moleculon',\n",
              " 'monchecourt',\n",
              " 'muscolina',\n",
              " 'nagymaros',\n",
              " 'nekoosa',\n",
              " 'nesb',\n",
              " 'nih-appointed',\n",
              " 'nipponese',\n",
              " 'nissho-iwai',\n",
              " 'northy',\n",
              " 'norwick',\n",
              " 'ntg',\n",
              " 'old-house',\n",
              " 'pattenden',\n",
              " 'pennview',\n",
              " 'pramual',\n",
              " 'pro-forma',\n",
              " 'purepac',\n",
              " 'rapanelli',\n",
              " 'ratners',\n",
              " 'red-blooded',\n",
              " 'retin-a',\n",
              " 'rexinger',\n",
              " 'romanee-conti',\n",
              " 'rubinfien',\n",
              " 'sacramento-based',\n",
              " 'samnick',\n",
              " 'sanderoff',\n",
              " 'satrum',\n",
              " 'secilia',\n",
              " 'senate-house',\n",
              " 'sharedata',\n",
              " 'sino-u.s.',\n",
              " 'solaia',\n",
              " 'stirlen',\n",
              " 'synergistics',\n",
              " 'tarwhine',\n",
              " 'times-stock',\n",
              " 'tiphook',\n",
              " 'trettien',\n",
              " 'trockenbeerenauslesen',\n",
              " 'univest',\n",
              " 'uzi-model',\n",
              " 'veselich',\n",
              " 'vinken',\n",
              " 'vitulli',\n",
              " 'we-japanese',\n",
              " 'weisfield',\n",
              " 'wfrr',\n",
              " 'wheeland',\n",
              " 'wtd',\n",
              " 'yeargin'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd-mhGDslXWm"
      },
      "source": [
        "# [Task 3 - 1.0 points] Model definition\n",
        "\n",
        "You are now tasked to define your neural POS tagger."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH9BPBwQlXWn"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n",
        "* You are **free** to experiment with hyper-parameters to define the baseline model.\n",
        "\n",
        "* **Model 1**: add an additional LSTM layer to the Baseline model.\n",
        "* **Model 2**: add an additional Dense layer to the Baseline model.\n",
        "\n",
        "* **Do not mix Model 1 and Model 2**. Each model has its own instructions.\n",
        "\n",
        "**Note**: if a document contains many tokens, you are **free** to split them into chunks or sentences to define your mini-batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u4X9kPliLIjR",
        "ExecuteTime": {
          "end_time": "2023-11-25T11:02:41.201284Z",
          "start_time": "2023-11-25T11:02:41.120556Z"
        }
      },
      "outputs": [],
      "source": [
        " # SoftMax is not necessary when using cross-entropy in Pytorch\n",
        "\n",
        "class BaselineModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_classes, embedding_matrix, padding_idx):\n",
        "        super(BaselineModel, self).__init__()\n",
        "\n",
        "        # Embedding layer with pre-trained weights\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx).from_pretrained(embedding_matrix, freeze=False)\n",
        "\n",
        "        # Bidirectional LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Dense layer\n",
        "        self.linear = nn.Linear(hidden_size * 2, num_classes)  # Multiply by 2 for bidirectional\n",
        "\n",
        "        # Potential softmax layer -> self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        hidden_vectors, _ = self.lstm(x)\n",
        "        x = self.linear(hidden_vectors)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Model1(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_classes, embedding_matrix, padding_idx):\n",
        "        super(Model1, self).__init__()\n",
        "\n",
        "        # Embedding layer with pre-trained weights\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx).from_pretrained(embedding_matrix, freeze=False)\n",
        "\n",
        "        # Two layers of Bidirectional LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True, bidirectional=True, num_layers=2)\n",
        "\n",
        "        # Dense layer\n",
        "        self.linear = nn.Linear(hidden_size * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        hidden_vectors, _ = self.lstm(x)\n",
        "        x = self.linear(hidden_vectors)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Model2(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_classes, embedding_matrix, padding_idx):\n",
        "        super(Model2, self).__init__()\n",
        "\n",
        "        # Embedding layer with pre-trained weights\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx).from_pretrained(embedding_matrix, freeze=False)\n",
        "\n",
        "        # Bidirectional LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Dense layer\n",
        "        self.linear1 = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "\n",
        "        # Dense layer\n",
        "        self.linear2 = nn.Linear(hidden_size * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        hidden_vectors, _ = self.lstm(x)\n",
        "        x = self.linear1(hidden_vectors)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gE5b6vuKLOdv"
      },
      "source": [
        "Let's create an embedding using the pre-trained Glove Embedding for each word in our vocabulary. If the word is OOV, we will instantiate an embedding that only consists of zeros.\n",
        "\n",
        "If the input word is unknown <UNK> the embedding result is always the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "n_azHBoAM-qc",
        "ExecuteTime": {
          "end_time": "2023-11-25T11:03:57.377391Z",
          "start_time": "2023-11-25T11:03:57.333612Z"
        }
      },
      "outputs": [],
      "source": [
        "def get_word_embedding(embedding_model, word: str, embedding_dim: int, random_seed: int = 42) -> np.ndarray:\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    if word == '<PAD>':\n",
        "        return np.zeros(embedding_dim)\n",
        "    elif word == '<UNK>':\n",
        "        return generate_consistent_random_embedding(word, embedding_dim)\n",
        "    else:\n",
        "        try:\n",
        "            return embedding_model[word]\n",
        "        except KeyError:\n",
        "            return generate_consistent_random_embedding(word, embedding_dim)\n",
        "\n",
        "def generate_consistent_random_embedding(word: str, embedding_dim: int) -> np.ndarray:\n",
        "    # Use a hash function to generate a unique number for the word\n",
        "    hash_value = int(hashlib.sha256(word.encode('utf-8')).hexdigest(), 16)\n",
        "    np.random.seed(hash_value % (2**32 - 1))  # Use the hash value as a seed\n",
        "\n",
        "    return np.random.uniform(low=-1, high=1, size=embedding_dim)\n",
        "\n",
        "def pad_sequences(sequences, max_length, padding_idx=0):\n",
        "    # Convert sequences to tensor\n",
        "    sequence_tensors = [torch.tensor(sequence) for sequence in sequences]\n",
        "\n",
        "    # Pad each sequence to the maximum length\n",
        "    padded_sequences = [torch.nn.functional.pad(seq, (0, max_length - len(seq)), 'constant', padding_idx) for seq in sequence_tensors]\n",
        "\n",
        "    # Stack the sequences into a single tensor\n",
        "    padded_sequences = torch.stack(padded_sequences)\n",
        "\n",
        "    return padded_sequences\n",
        "\n",
        "def features_tokenizer(sorted_vocabulary: pd.Series, words: pd.Series) -> pd.Series:\n",
        "    word_to_index = {word: i for i, word in enumerate(sorted_vocabulary)}\n",
        "\n",
        "    def tokenize_single_word(word):\n",
        "        return word_to_index.get(word, word_to_index[\"<UNK>\"]) # If word is not in dictionary, it returns default \"word_to_index[<UNK>]\"\n",
        "\n",
        "    return words.apply(tokenize_single_word)\n",
        "\n",
        "def labels_tokenizer(sorted_vocabulary: pd.Series, words: pd.Series) -> pd.Series:\n",
        "    word_to_index = {word: i for i, word in enumerate(sorted_vocabulary)}\n",
        "\n",
        "    def tokenize_single_word(word):\n",
        "        return word_to_index[word]\n",
        "\n",
        "    return words.apply(tokenize_single_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1C0zxRgKt5C",
        "outputId": "ec611229-79ba-48ce-c28d-df8d09087aab",
        "ExecuteTime": {
          "end_time": "2023-11-25T11:05:00.272173Z",
          "start_time": "2023-11-25T11:05:00.110002Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is <UNK> already in the vocabulary?: False\n",
            "Is <PAD> already in the vocabulary?: False\n",
            "\n",
            "Size of the vocabulary is 7406\n",
            "Size of the POS target set is 45\n"
          ]
        }
      ],
      "source": [
        "# Sorting out our vocabulary train in alphabetical order, after having dropped duplicates\n",
        "vocabulary = train['value'].drop_duplicates().sort_values()\n",
        "\n",
        "print(f\"Is <UNK> already in the vocabulary?: {'<UNK>' in train['value'].drop_duplicates().sort_values()}\")\n",
        "print(f\"Is <PAD> already in the vocabulary?: {'<PAD>' in train['value'].drop_duplicates().sort_values()}\")\n",
        "\n",
        "# Add padding token\n",
        "features_vocabulary = pd.concat([pd.Series([\"<PAD>\"]), pd.Series([\"<UNK>\"]), vocabulary]).reset_index(drop=True)\n",
        "features_vocabulary_size = len(features_vocabulary)\n",
        "print(f\"\\nSize of the vocabulary is {features_vocabulary_size}\")\n",
        "\n",
        "labels_vocabulary = train['pos_label'].drop_duplicates().sort_values().reset_index(drop=True)\n",
        "labels_vocabulary_size = len(labels_vocabulary)\n",
        "print(f\"Size of the POS target set is {labels_vocabulary_size}\")\n",
        "\n",
        "word_to_embedding = {word: get_word_embedding(embedding_model, word, embedding_dim, 42) for i, word in enumerate(features_vocabulary)}\n",
        "\n",
        "embedding_matrix = np.vstack(list(word_to_embedding.values()))\n",
        "\n",
        "# Create PyTorch tensor to use in models\n",
        "embedding_tensor = torch.tensor(embedding_matrix, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_into_sentences(df):\n",
        "    # Identify the end of sentences (rows where 'value' is '.')\n",
        "    sentence_end_mask = df['value'] == '.'\n",
        "\n",
        "    # Shift the mask by one row so that the period is included in the current sentence\n",
        "    shifted_sentence_end_mask = sentence_end_mask.shift(1, fill_value=False)\n",
        "\n",
        "    # Add an extra column for sentence indices\n",
        "    df['sentence_idx'] = shifted_sentence_end_mask.cumsum()\n",
        "\n",
        "    # Split the dataframe into a list of dataframes, each representing a sentence\n",
        "    sentences = [sentence_df for _, sentence_df in df.groupby('sentence_idx')]\n",
        "\n",
        "    return pd.concat(sentences)\n",
        "\n",
        "# Usage\n",
        "train_with_sentences = split_into_sentences(train)\n",
        "validation_with_sentences = split_into_sentences(validation)\n",
        "test_with_sentences = split_into_sentences(test)\n",
        "\n",
        "train_with_sentences.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kNkhHwACXgXw",
        "outputId": "6408c0e4-8a3e-40bc-b677-90223fda388b",
        "ExecuteTime": {
          "end_time": "2023-11-25T11:06:01.175741Z",
          "start_time": "2023-11-25T11:06:00.734629Z"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    value pos_label  doc_idx  sentence_idx\n",
              "0  pierre       NNP        1             0\n",
              "1  vinken       NNP        1             0\n",
              "2       ,         ,        1             0\n",
              "3      61        CD        1             0\n",
              "4   years       NNS        1             0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-150b6028-a534-4fcc-8819-e9668c51ebeb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>value</th>\n",
              "      <th>pos_label</th>\n",
              "      <th>doc_idx</th>\n",
              "      <th>sentence_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pierre</td>\n",
              "      <td>NNP</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vinken</td>\n",
              "      <td>NNP</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "      <td>CD</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>years</td>\n",
              "      <td>NNS</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-150b6028-a534-4fcc-8819-e9668c51ebeb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-150b6028-a534-4fcc-8819-e9668c51ebeb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-150b6028-a534-4fcc-8819-e9668c51ebeb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a470273f-375e-45bc-81c5-9805e95a3603\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a470273f-375e-45bc-81c5-9805e95a3603')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a470273f-375e-45bc-81c5-9805e95a3603 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCMjP_-9ffMt",
        "outputId": "8886173d-9efa-4a7f-d006-1e5d2ca35244",
        "ExecuteTime": {
          "end_time": "2023-11-25T11:06:55.259527Z",
          "start_time": "2023-11-25T11:06:45.915270Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum length of a document in training set is 250\n",
            "The maximum length of a document in validation set is 88\n",
            "The maximum length of a document in test set is 80\n"
          ]
        }
      ],
      "source": [
        "train_padding_max_length = 0\n",
        "for sentence_idx in train_with_sentences['sentence_idx'].unique():\n",
        "  train_padding_max_length = max(sum(train_with_sentences['sentence_idx'] == sentence_idx), train_padding_max_length)\n",
        "\n",
        "print(f\"The maximum length of a document in training set is {train_padding_max_length}\")\n",
        "\n",
        "validation_padding_max_length = 0\n",
        "for sentence_idx in validation_with_sentences['sentence_idx'].unique():\n",
        "  validation_padding_max_length = max(sum(validation_with_sentences['sentence_idx'] == sentence_idx), validation_padding_max_length)\n",
        "print(f\"The maximum length of a document in validation set is {validation_padding_max_length}\")\n",
        "\n",
        "test_padding_max_length = 0\n",
        "for sentence_idx in test_with_sentences['sentence_idx'].unique():\n",
        "  test_padding_max_length = max(sum(test_with_sentences['sentence_idx'] == sentence_idx), test_padding_max_length)\n",
        "print(f\"The maximum length of a document in test set is {test_padding_max_length}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a function to generate x and y splits for our train, validation and test set as below. In particular, the input of our function will be:\n",
        "\n",
        "* dataframe_list: a list of the dataframes we need to split, in our case train, validation and test.\n",
        "* padding_max_length: the maximum lenght of our padded sequences\n",
        "* features_vovabulary: vocabulary of our features\n",
        "* labels_vovabulary: vocabulary of our labels"
      ],
      "metadata": {
        "id": "mxsbeuEzMdib"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4LReXMrrUuU1",
        "ExecuteTime": {
          "end_time": "2023-11-25T11:08:25.604521Z",
          "start_time": "2023-11-25T11:08:24.597206Z"
        }
      },
      "outputs": [],
      "source": [
        "def train_test_val_splits(dataframe_list: List[pd.DataFrame], padding_max_length: int, features_vocabulary: pd.Series, labels_vocabulary: pd.Series) -> Tuple[torch.Tensor, ...]:\n",
        "    padded_data = list()\n",
        "\n",
        "    for dataframe in dataframe_list:\n",
        "        # Map words and POS labels to indices\n",
        "        dataframe['word_token'] = features_tokenizer(features_vocabulary, dataframe['value'])\n",
        "        dataframe['pos_token'] = labels_tokenizer(labels_vocabulary, dataframe['pos_label'])\n",
        "\n",
        "        # Group by document index and aggregate as lists\n",
        "        grouped_per_doc = dataframe.groupby('sentence_idx').agg(list)\n",
        "\n",
        "        # Extract and pad sequences\n",
        "        x_padded = pad_sequences(grouped_per_doc['word_token'].tolist(), padding_max_length)\n",
        "        y_padded = pad_sequences(grouped_per_doc['pos_token'].tolist(), padding_max_length)\n",
        "\n",
        "        padded_data.append((x_padded, y_padded))\n",
        "\n",
        "    # Unpack the padded data for train, validation, and test sets\n",
        "    x_train, y_train = padded_data[0]\n",
        "    x_val, y_val = padded_data[1]\n",
        "    x_test, y_test = padded_data[2]\n",
        "\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
        "\n",
        "x_train, y_train, x_val, y_val, x_test, y_test = train_test_val_splits([train_with_sentences, validation_with_sentences, test_with_sentences], max(train_padding_max_length, validation_padding_max_length), features_vocabulary, labels_vocabulary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKEdFKRwlXWp"
      },
      "source": [
        "# [Task 4 - 1.0 points] Metrics\n",
        "\n",
        "Before training the models, you are tasked to define the evaluation metrics for comparison."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaCThuLQlXWq"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Evaluate your models using macro F1-score, compute over **all** tokens.\n",
        "* **Concatenate** all tokens in a data split to compute the F1-score. (**Hint**: accumulate FP, TP, FN, TN iteratively)\n",
        "* **Do not consider punctuation and symbol classes** $\\rightarrow$ [What is punctuation?](https://en.wikipedia.org/wiki/English_punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwJfumzVlXWr"
      },
      "source": [
        "**Note**: What about OOV tokens?\n",
        "   * All the tokens in the **training** set that are not in GloVe are **not** considered as OOV\n",
        "   * For the remaining tokens (i.e., OOV in the validation and test sets), you have to assign them a **static** embedding.\n",
        "   * You are **free** to define the static embedding using any strategy (e.g., random, neighbourhood, etc...)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_f1(model, x: torch.Tensor, y: torch.Tensor) -> float:\n",
        "\n",
        "  def remove_punctuation_and_symbols(y: torch.Tensor, preds: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    indices = [idx for idx, token in enumerate(y) if labels_vocabulary[token.item()].isalnum()]\n",
        "    return y[indices], preds[indices]\n",
        "\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  preds = infer(model, x, device).cpu()\n",
        "\n",
        "  y, preds = remove_punctuation_and_symbols(y.flatten(), preds.flatten())\n",
        "\n",
        "  return f1_score(y, preds, average=\"macro\")"
      ],
      "metadata": {
        "id": "8j08jiJwQYmd",
        "ExecuteTime": {
          "end_time": "2023-11-25T11:09:08.063937Z",
          "start_time": "2023-11-25T11:09:07.990407Z"
        }
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUePkadNlXWt"
      },
      "source": [
        "# [Task 5 - 1.0 points] Training and Evaluation\n",
        "\n",
        "You are now tasked to train and evaluate the Baseline, Model 1, and Model 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya7j94pjlXWu"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Train **all** models on the train set.\n",
        "* Evaluate **all** models on the validation set.\n",
        "* Compute metrics on the validation set.\n",
        "* Pick **at least** three seeds for robust estimation.\n",
        "* Pick the **best** performing model according to the observed validation set performance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_model(model, train_dataloader, val_dataloader, num_epochs, loss_func, optimizer, device, patience, min_delta) -> Tuple[float, List[float]]:\n",
        "    total_steps = len(train_dataloader)\n",
        "    best_val_loss = float('inf')\n",
        "    all_loss: List[float] = list()\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        for batch_idx, (inputs, labels) in enumerate(train_dataloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(inputs)\n",
        "            output = output.view(-1, output.shape[-1])\n",
        "            labels = labels.view(-1)\n",
        "\n",
        "            # Loss calculation and backpropagation\n",
        "            loss = loss_func(output, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / total_steps\n",
        "\n",
        "        # Validation Phase\n",
        "        model.eval()\n",
        "        f1_score_val: float = compute_f1(model, x_val, y_val)\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_dataloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                output = model(inputs)\n",
        "                output = output.view(-1, output.shape[-1])\n",
        "                labels = labels.view(-1)\n",
        "\n",
        "                # Loss calculation\n",
        "                loss = loss_func(output, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_dataloader)\n",
        "        all_loss.append(avg_val_loss)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Validation F1-score: {f1_score_val:.2%}\")\n",
        "\n",
        "        # Early Stopping Check\n",
        "        if avg_val_loss < best_val_loss - min_delta:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f'Early stopping triggered. Stopping training after {epoch+1} epochs.')\n",
        "                break\n",
        "    return f1_score_val, all_loss"
      ],
      "metadata": {
        "id": "6eBZWMl3HlRW",
        "ExecuteTime": {
          "end_time": "2023-11-25T11:09:34.177548Z",
          "start_time": "2023-11-25T11:09:34.154755Z"
        }
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infer(model, input_document, device: str):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(input_document.to(device))\n",
        "        predictions = torch.argmax(output, dim=-1)  # Get the index of the max log-probability\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "FgAIDfaah3LG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "def download_model(model_name, file_id):\n",
        "    url = f'https://drive.google.com/uc?id={file_id}'\n",
        "    output = f\"{model_name}.pt\"\n",
        "    if not os.path.exists(output):\n",
        "        urllib.request.urlretrieve(url, output)\n",
        "    return torch.load(output, map_location=torch.device('cpu'))\n",
        "\n",
        "\n",
        "def download_table(table_name, file_id):\n",
        "    url = f'https://drive.google.com/uc?id={file_id}'\n",
        "    output = f\"{table_name}.csv\"\n",
        "    if not os.path.exists(output):\n",
        "        urllib.request.urlretrieve(url, output)\n",
        "    return pd.read_csv(output)\n"
      ],
      "metadata": {
        "id": "1LfTUIpufDgZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_urls = {\n",
        "    \"BaselineModel_42\": \"1UZ1nVYWqs3IGioEwK0huBnYYw0XKLbQR\",\n",
        "    \"Model1_42\": \"1FfrxWF5-Qnm3lMpm3xZNIepumlzYXg2-\",\n",
        "    \"Model2_42\": \"1_Fev2Viwg1_XLwqU206wLnGI7mfTtYuG\",\n",
        "    \"BaselineModel_1024\": \"1EVCVQ1Uy-95XMJ9r0REbPNGZU9fZCK5f\",\n",
        "    \"Model1_1024\": \"1qMJV-9Du0ZMMxSOtTBlzRI-BYaewaJro\",\n",
        "    \"Model2_1024\": \"13Qp98AiyEg8P1dpD0jxt5Fj6Jms5vOfD\",\n",
        "    \"BaselineModel_4096\": \"1GMgey95wN6JIyKQ2xvZVdT7uKNFRKwkq\",\n",
        "    \"Model1_4096\": \"194opT3xs6qVJTFXrR91fGyJaQ9u-Pc4d\",\n",
        "    \"Model2_4096\": \"1fb3OxGiXISiUvyhA3DPnsGTKJvOe5jPE\",\n",
        "}\n",
        "\n",
        "train_models = False\n",
        "seeds: List[int] = [42, 1024, 4096]\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "epochs: int = 100\n",
        "train_batch_size: int = 32\n",
        "val_batch_size: int = 32\n",
        "lr: float = 1e-4\n",
        "padding_idx: int = 0\n",
        "patience: int = 100\n",
        "min_delta: float = 1e-3\n",
        "\n",
        "if train_models == False:\n",
        "    models_data_file_id = '1YC28hDvB7-gBe3DP9zNK63ME04rGTOMC'\n",
        "    csv_filename = 'models_data.csv'\n",
        "    models_data = download_table(csv_filename, models_data_file_id)\n",
        "    models_data['model_name'] = pd.Series(model_urls.keys())\n",
        "    models_data['model_url'] = pd.Series(model_urls.values())\n",
        "    pre_trained_models = {model: np.nan for model in model_urls.keys()}\n",
        "\n",
        "    for seed in seeds:\n",
        "      if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "          np.random.seed(seed)\n",
        "          random.seed(seed)\n",
        "          if torch.cuda.is_available():\n",
        "              torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "      # Create a TensorDataset and DataLoader for training data\n",
        "      train_dataset = TensorDataset(x_train, y_train)\n",
        "      train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
        "\n",
        "      # BaselineModel\n",
        "      baseline_model_name = f\"BaselineModel_{seed}\"\n",
        "      if baseline_model_name in model_urls:\n",
        "          print(f\"Attempting to download {baseline_model_name}...\")\n",
        "          baseline_model = download_model(baseline_model_name, model_urls[baseline_model_name])\n",
        "          print(f\"Successfully downloaded {baseline_model_name}!\")\n",
        "          pre_trained_models[baseline_model_name] = baseline_model\n",
        "\n",
        "      # BaselineModel\n",
        "      model1_name = f\"Model1_{seed}\"\n",
        "      if model1_name in model_urls:\n",
        "          print(f\"Attempting to download {baseline_model_name}...\")\n",
        "          model_1 = download_model(model1_name, model_urls[model1_name])\n",
        "          print(f\"Successfully downloaded {baseline_model_name}!\")\n",
        "          pre_trained_models[model1_name] = model_1\n",
        "\n",
        "      # BaselineModel\n",
        "      model2_name = f\"Model2{seed}\"\n",
        "      if model2_name in model_urls:\n",
        "          print(f\"Attempting to download {model2_name}...\")\n",
        "          model_2 = download_model(model2_name, model_urls[model2_name])\n",
        "          print(f\"Successfully downloaded {baseline_model_name}!\")\n",
        "          pre_trained_models[model2_name] = model_2\n",
        "\n",
        "    best_model_name = models_data[models_data['f1_score'] == models_data['f1_score'].max()]['model_name'].iloc[0]\n",
        "    print(f\"The model with the highest f1_score is: {best_model_name} with a score of {models_data['f1_score'].max():.2%}.\")\n",
        "    if \"BaselineModel\" in best_model_name:\n",
        "      best_model = BaselineModel(features_vocabulary_size, embedding_dim, embedding_dim, labels_vocabulary_size, embedding_tensor, padding_idx=padding_idx).to(device)\n",
        "    elif \"Model1\" in best_model_name:\n",
        "      best_model = Model1(features_vocabulary_size, embedding_dim, embedding_dim, labels_vocabulary_size, embedding_tensor, padding_idx=padding_idx).to(device)\n",
        "    elif \"Model2\" in best_model_name:\n",
        "      best_model = Model2(features_vocabulary_size, embedding_dim, embedding_dim, labels_vocabulary_size, embedding_tensor, padding_idx=padding_idx).to(device)\n",
        "    best_model.load_state_dict(pre_trained_models[best_model_name])\n",
        "    best_model.eval()\n",
        "\n",
        "\n",
        "if train_models == True:\n",
        "\n",
        "  # Create a TensorDataset and DataLoader for validation data\n",
        "  val_dataset = TensorDataset(x_val, y_val)\n",
        "  val_dataloader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=False)  # Shuffle is usually False for validation/test sets\n",
        "\n",
        "  models: Dict[str, Any] = {\"model\": [], \"random_seed\": [], \"f1_score\": [], \"all_loss\": []}\n",
        "  best_models: Dict[str, Dict[str, Any]] = {\"baseline_model\": {\"model\": None, \"f1_score\": -np.inf}, \"model_1\": {\"model\": None, \"f1_score\": -np.inf}, \"model_2\": {\"model\": None, \"f1_score\": -np.inf}}\n",
        "\n",
        "  for seed in seeds:\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        random.seed(seed)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    # Create a TensorDataset and DataLoader for training data (put here for setting seed)\n",
        "    train_dataset = TensorDataset(x_train, y_train)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
        "\n",
        "    #baseline_model = BaselineModel(features_vocabulary_size, embedding_dim, embedding_dim, labels_vocabulary_size, embedding_tensor, padding_idx=padding_idx).to(device)\n",
        "    #optimizer = optim.Adam(baseline_model.parameters(), lr=lr)\n",
        "    #print(f\"\\nTraining baseline_model with seed {seed}\")\n",
        "    #f1_score_val, all_loss = training_model(baseline_model, train_dataloader, val_dataloader, epochs, loss_func, optimizer, device, patience, min_delta)\n",
        "    #models[\"model\"].append(baseline_model)\n",
        "    #models[\"random_seed\"].append(seed)\n",
        "    #models[\"f1_score\"].append(f1_score_val)\n",
        "    #models[\"all_loss\"].append(all_loss)\n",
        "    #if best_models[\"baseline_model\"][\"f1_score\"] < f1_score_val:\n",
        "    #  best_models[\"baseline_model\"][\"f1_score\"] = f1_score_val\n",
        "    #  best_models[\"baseline_model\"][\"model\"] = baseline_model\n",
        "\n",
        "    model_1 = Model1(features_vocabulary_size, embedding_dim, embedding_dim, labels_vocabulary_size, embedding_tensor, padding_idx=padding_idx).to(device)\n",
        "    optimizer = optim.Adam(model_1.parameters(), lr=lr)\n",
        "    print(f\"\\nTraining model_1 with seed {seed}\")\n",
        "    f1_score_val, all_loss = training_model(model_1, train_dataloader, val_dataloader, epochs, loss_func, optimizer, device, patience, min_delta)\n",
        "    models[\"model\"].append(model_1)\n",
        "    models[\"random_seed\"].append(seed)\n",
        "    models[\"f1_score\"].append(f1_score_val)\n",
        "    models[\"all_loss\"].append(all_loss)\n",
        "    if best_models[\"model_1\"][\"f1_score\"] < f1_score_val:\n",
        "      best_models[\"model_1\"][\"f1_score\"] = f1_score_val\n",
        "      best_models[\"model_1\"][\"model\"] = model_1\n",
        "\n",
        "    model_2 = Model2(features_vocabulary_size, embedding_dim, embedding_dim, labels_vocabulary_size, embedding_tensor, padding_idx=padding_idx).to(device)\n",
        "    optimizer = optim.Adam(model_2.parameters(), lr=lr)\n",
        "    print(f\"\\nTraining model_2 with seed {seed}\")\n",
        "    f1_score_val, all_loss = training_model(model_2, train_dataloader, val_dataloader, epochs, loss_func, optimizer, device, patience, min_delta)\n",
        "    models[\"model\"].append(model_2)\n",
        "    models[\"random_seed\"].append(seed)\n",
        "    models[\"f1_score\"].append(f1_score_val)\n",
        "    models[\"all_loss\"].append(all_loss)\n",
        "    if best_models[\"model_2\"][\"f1_score\"] < f1_score_val:\n",
        "      best_models[\"model_2\"][\"f1_score\"] = f1_score_val\n",
        "    best_models[\"model_2\"][\"model\"] = model_2\n",
        "\n",
        "  best_model = max(best_models.items(), key=lambda x: x[1][\"f1_score\"])\n",
        "  print(f\"The model with the highest f1_score is: {best_model[0]} with a score of {best_model[1]['f1_score']:.2%}.\")\n",
        "  best_model = best_model[1][\"model\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlFrdjzhhEJs",
        "outputId": "1752027e-f0a5-491f-d125-39579598930e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to download BaselineModel_42...\n",
            "Successfully downloaded BaselineModel_42!\n",
            "Attempting to download BaselineModel_42...\n",
            "Successfully downloaded BaselineModel_42!\n",
            "Attempting to download BaselineModel_1024...\n",
            "Successfully downloaded BaselineModel_1024!\n",
            "Attempting to download BaselineModel_1024...\n",
            "Successfully downloaded BaselineModel_1024!\n",
            "Attempting to download BaselineModel_4096...\n",
            "Successfully downloaded BaselineModel_4096!\n",
            "Attempting to download BaselineModel_4096...\n",
            "Successfully downloaded BaselineModel_4096!\n",
            "The model with the highest f1_score is: BaselineModel_4096 with a score of 65.74%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-rqlmZ8lXWv"
      },
      "source": [
        "# [Task 6 - 1.0 points] Error Analysis\n",
        "\n",
        "You are tasked to evaluate your best performing model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuGCPAfZlXWx"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Compare the errors made on the validation and test sets.\n",
        "* Aggregate model errors into categories (if possible)\n",
        "* Comment the about errors and propose possible solutions on how to address them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "BUCMrnjXTfAE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2988497-bd70-4214-88e3-34af9aec470f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratio of correct tags: 96.4%\n",
            "\n",
            "+----------+---------+---------+----------+---------+---------+---------+----------+---------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "|    \\     | Token 1 | Token 2 | Token 3  | Token 4 | Token 5 | Token 6 | Token 7  | Token 8 | Token 9 | Token 10 | Token 11 | Token 12 | Token 13 | Token 14 | Token 15 | Token 16 | Token 17 | Token 18 |   Token 19   | Token 20 | Token 21 | Token 22 | Token 23 | Token 24 | Token 25 | Token 26 | Token 27 | Token 28 |\n",
            "+----------+---------+---------+----------+---------+---------+---------+----------+---------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "| Document |   mr.   |  <UNK>  | declined |    to   |  <UNK>  |   what  | prompted |   the   |  recent |  moves   |    ,     |  saying  |   they   |   are    |  meant   |   only   |    to    |  <UNK>   | shareholders |   when   |    ``    |   the    | company  |    is    |    on    |    a     |   roll   |    .     |\n",
            "|  Target  |   NNP   |   NNP   |   VBD    |    TO   |    VB   |    WP   |   VBD    |    DT   |    JJ   |   NNS    |    ,     |   VBG    |   PRP    |   VBP    |   VBN    |    RB    |    TO    |    VB    |     NNS      |   WRB    |    ``    |    DT    |    NN    |   VBZ    |    IN    |    DT    |    NN    |    .     |\n",
            "|   Pred   |   NNP   |   \u001b[91mVBN\u001b[0m   |   VBD    |    TO   |    VB   |    WP   |   VBD    |    DT   |    JJ   |   NNS    |    ,     |   VBG    |   PRP    |   VBP    |   VBN    |    RB    |    TO    |    VB    |     NNS      |   WRB    |    ``    |    DT    |    NN    |   VBZ    |    IN    |    DT    |    NN    |    .     |\n",
            "+----------+---------+---------+----------+---------+---------+---------+----------+---------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n"
          ]
        }
      ],
      "source": [
        "def print_error_analysis(model: nn.Module, x: np.array, y:np.array, idx: int, pad_token_idx: int = 0) -> None:\n",
        "  pred_pos_tags = infer(model, x[idx], device).cpu()\n",
        "  target_pos_tags: torch.Tensor = y[idx].cpu()\n",
        "\n",
        "  # Take the tokens that shouldn't be padding\n",
        "  pred_pos_tags_no_padding: torch.Tensor = pred_pos_tags[target_pos_tags != pad_token_idx]\n",
        "  target_pos_tags_no_padding: torch.Tensor = target_pos_tags[target_pos_tags != pad_token_idx]\n",
        "\n",
        "  document: List[str] = [features_vocabulary[index.item()] for index in x[idx][target_pos_tags != pad_token_idx]]\n",
        "  target_tags: List[str] = [labels_vocabulary[index.item()] for index in target_pos_tags_no_padding]\n",
        "\n",
        "  pred_tags: List[str] = [\"\\033[91m{}\\033[0m\".format(pred_tag) if pred_tag != target_tags[i] else pred_tag for i, pred_tag in enumerate(labels_vocabulary[index.item()] for index in pred_pos_tags_no_padding)]\n",
        "\n",
        "  ratio_correct_tags: float = (sum(target_pos_tags_no_padding == pred_pos_tags_no_padding) / len(target_pos_tags_no_padding)).item()\n",
        "  print(f\"Ratio of correct tags: {ratio_correct_tags:.1%}\\n\")\n",
        "\n",
        "  table = PrettyTable()\n",
        "  table.field_names = [\"\\\\\"] + [f\"Token {i+1}\" for i in range(len(document))]\n",
        "\n",
        "  table.add_row([\"Document\"] + [col.strip() for col in document])\n",
        "  table.add_row([\"Target\"] + [col.strip() for col in target_tags])\n",
        "  table.add_row([\"Pred\"] + [col.strip() for col in pred_tags])\n",
        "  print(table)\n",
        "\n",
        "print_error_analysis(best_model, x_test, y_test, idx=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def performance_by_class_frequency(model, X, Y, labels_vocabulary, pad_token_idx=0):\n",
        "    filtered_preds = []\n",
        "    filtered_targets = []\n",
        "\n",
        "    # Iterate over each example in the dataset\n",
        "    for x, y in zip(X, Y):\n",
        "        # Generate predictions\n",
        "        preds = infer(model, x, device).cpu()\n",
        "\n",
        "        # Filter predictions and targets together, excluding padding and missing labels\n",
        "        for pred, target in zip(preds, y):\n",
        "            target_idx = target.item()\n",
        "            pred_idx = pred.item()\n",
        "            if target_idx != pad_token_idx and target_idx in labels_vocabulary and labels_vocabulary[target_idx].isalnum():\n",
        "                filtered_preds.append(pred_idx)\n",
        "                filtered_targets.append(target_idx)\n",
        "\n",
        "    # Calculate class frequencies for filtered targets\n",
        "    class_frequencies = Counter(filtered_targets)\n",
        "\n",
        "    # Identify present classes in filtered targets and predictions\n",
        "    present_classes = sorted(set(filtered_targets + filtered_preds))\n",
        "    filtered_labels = [labels_vocabulary[i] for i in present_classes if i in labels_vocabulary]\n",
        "\n",
        "    # Performance metrics by class\n",
        "    report = classification_report(filtered_targets, filtered_preds, target_names=filtered_labels, zero_division=0)\n",
        "    report_dict = classification_report(filtered_targets, filtered_preds, target_names=filtered_labels, zero_division=0, output_dict=True)\n",
        "\n",
        "    overall_precision = precision_score(filtered_targets, filtered_preds, average='macro')\n",
        "    overall_recall = recall_score(filtered_targets, filtered_preds, average='macro')\n",
        "    overall_f1_score = f1_score(filtered_targets, filtered_preds, average='macro')\n",
        "\n",
        "    print(f\"Overall macro precision: {overall_precision:.2%}\")\n",
        "    print(f\"Overall macro recall: {overall_recall:.2%}\")\n",
        "    print(f\"Overall macro F1-score: {overall_f1_score:.2%}\")\n",
        "\n",
        "    return report, report_dict, class_frequencies"
      ],
      "metadata": {
        "id": "X_e4xLYnYa12",
        "ExecuteTime": {
          "end_time": "2023-11-25T11:24:53.715201Z",
          "start_time": "2023-11-25T11:24:53.673975Z"
        }
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_metrics(report):\n",
        "    metrics_dict = {}\n",
        "    for label, metrics in report.items():\n",
        "        if label in ['accuracy', 'macro avg', 'weighted avg']:\n",
        "            continue\n",
        "        metrics_dict[label] = {\n",
        "            'precision': metrics['precision'],\n",
        "            'recall': metrics['recall'],\n",
        "            'f1-score': metrics['f1-score']\n",
        "        }\n",
        "    return metrics_dict\n",
        "\n",
        "def correlate_metrics_with_frequency(report_dict, class_frequencies):\n",
        "    metrics_dict = extract_metrics(report_dict)\n",
        "\n",
        "    # Prepare data for correlation\n",
        "    data = []\n",
        "    for label, metrics in metrics_dict.items():\n",
        "        if label in class_frequencies:\n",
        "            data.append({\n",
        "                'Class': label,\n",
        "                'Precision': metrics['precision'],\n",
        "                'Recall': metrics['recall'],\n",
        "                'F1-score': metrics['f1-score'],\n",
        "                'Frequency': class_frequencies[label]\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Calculate correlations\n",
        "    precision_corr = df[['Precision', 'Frequency']].corr().iloc[0, 1]\n",
        "    recall_corr = df[['Recall', 'Frequency']].corr().iloc[0, 1]\n",
        "    f1_score_corr = df[['F1-score', 'Frequency']].corr().iloc[0, 1]\n",
        "\n",
        "    return df.sort_values(by='Frequency', ascending=False), precision_corr, recall_corr, f1_score_corr"
      ],
      "metadata": {
        "id": "kzqQH9vX0ZDX"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Set\")\n",
        "report, report_dict, class_frequencies = performance_by_class_frequency(best_model, x_test, y_test, labels_vocabulary)\n",
        "_, precision_corr, recall_corr, f1_score_corr = correlate_metrics_with_frequency(report_dict, {labels_vocabulary[token]: class_frequencies[token] for token in [value for value in class_frequencies]})\n",
        "print(report)\n",
        "print(f\"Correlation between class frequency and Precision in test set: {precision_corr}\\n\")\n",
        "print(f\"Correlation between class frequency and Recall in test set: {recall_corr}\\n\")\n",
        "print(f\"Correlation between class frequency and F1-score in test set: {f1_score_corr}\")"
      ],
      "metadata": {
        "id": "1KLGkEw62P5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b5b1ba-57b5-4535-f2be-4109ecb27405"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set\n",
            "Overall macro precision: 80.95%\n",
            "Overall macro recall: 78.81%\n",
            "Overall macro F1-score: 78.28%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.99      1.00      1.00       366\n",
            "          CD       0.99      0.76      0.86       858\n",
            "          DT       0.99      0.99      0.99      1335\n",
            "          EX       0.83      1.00      0.91         5\n",
            "          IN       0.99      0.96      0.97      1630\n",
            "          JJ       0.68      0.85      0.76       918\n",
            "         JJR       0.80      0.75      0.77        59\n",
            "         JJS       0.94      0.97      0.95        31\n",
            "          MD       0.97      1.00      0.99       167\n",
            "          NN       0.90      0.80      0.85      2383\n",
            "         NNP       0.94      0.62      0.75      1504\n",
            "        NNPS       0.00      0.00      0.00        44\n",
            "         NNS       0.91      0.79      0.85       941\n",
            "         PDT       0.00      0.00      0.00         4\n",
            "         POS       0.99      1.00      1.00       152\n",
            "         PRP       1.00      0.99      1.00       192\n",
            "          RB       0.83      0.86      0.85       381\n",
            "         RBR       0.38      0.33      0.36        15\n",
            "         RBS       1.00      0.33      0.50         3\n",
            "          RP       0.48      0.76      0.59        33\n",
            "          TO       1.00      1.00      1.00       386\n",
            "          VB       0.82      0.95      0.88       403\n",
            "         VBD       0.90      0.86      0.88       634\n",
            "         VBG       0.89      0.64      0.74       221\n",
            "         VBN       0.23      0.83      0.36       366\n",
            "         VBP       0.96      0.80      0.87       134\n",
            "         VBZ       0.95      0.89      0.92       280\n",
            "         WDT       0.91      0.94      0.92        84\n",
            "          WP       1.00      1.00      1.00        20\n",
            "         WRB       1.00      0.96      0.98        24\n",
            "\n",
            "    accuracy                           0.85     13573\n",
            "   macro avg       0.81      0.79      0.78     13573\n",
            "weighted avg       0.90      0.85      0.86     13573\n",
            "\n",
            "Correlation between class frequency and Precision in test set: 0.2425993973864833\n",
            "\n",
            "Correlation between class frequency and Recall in test set: 0.1640464777630585\n",
            "\n",
            "Correlation between class frequency and F1-score in test set: 0.22270190349212357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Validation Set\")\n",
        "report, report_dict, class_frequencies = performance_by_class_frequency(best_model, x_val, y_val, labels_vocabulary)\n",
        "_, precision_corr, recall_corr, f1_score_corr = correlate_metrics_with_frequency(report_dict, {labels_vocabulary[token]: class_frequencies[token] for token in [value for value in class_frequencies]})\n",
        "print(report)\n",
        "print(f\"Correlation between class frequency and Precision in validation set: {precision_corr}\\n\")\n",
        "print(f\"Correlation between class frequency and Recall in validation set: {recall_corr}\\n\")\n",
        "print(f\"Correlation between class frequency and F1-score in validation set: {f1_score_corr}\")"
      ],
      "metadata": {
        "id": "A86Kjen4uvjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c6ec4ba-bfc5-4d85-8488-bf1d1cfa401b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Set\n",
            "Overall macro precision: 68.10%\n",
            "Overall macro recall: 66.02%\n",
            "Overall macro F1-score: 65.74%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           :       0.00      0.00      0.00         0\n",
            "          CC       1.00      0.99      0.99       758\n",
            "          CD       0.99      0.74      0.84      1249\n",
            "          DT       0.99      0.99      0.99      2754\n",
            "          EX       0.92      1.00      0.96        34\n",
            "          FW       0.00      0.00      0.00         2\n",
            "          IN       0.99      0.96      0.98      3275\n",
            "          JJ       0.69      0.83      0.76      1924\n",
            "         JJR       0.89      0.72      0.79       165\n",
            "         JJS       0.81      0.90      0.85        58\n",
            "          LS       0.00      0.00      0.00         3\n",
            "          MD       1.00      0.97      0.99       347\n",
            "          NN       0.86      0.83      0.85      4513\n",
            "         NNP       0.92      0.64      0.75      2704\n",
            "        NNPS       0.00      0.00      0.00       105\n",
            "         NNS       0.93      0.73      0.82      2102\n",
            "         PDT       0.00      0.00      0.00        14\n",
            "         POS       0.99      0.99      0.99       269\n",
            "         PRP       1.00      0.99      0.99       570\n",
            "        PRP$       0.00      0.00      0.00         0\n",
            "          RB       0.85      0.86      0.85       951\n",
            "         RBR       0.51      0.54      0.53        35\n",
            "         RBS       0.50      0.08      0.13        13\n",
            "          RP       0.46      0.70      0.56        43\n",
            "          TO       1.00      1.00      1.00       765\n",
            "          UH       0.00      0.00      0.00         2\n",
            "          VB       0.82      0.86      0.84       956\n",
            "         VBD       0.86      0.84      0.85       861\n",
            "         VBG       0.90      0.62      0.73       476\n",
            "         VBN       0.24      0.85      0.38       737\n",
            "         VBP       0.90      0.77      0.83       460\n",
            "         VBZ       0.96      0.84      0.89       712\n",
            "         WDT       0.89      0.89      0.89       157\n",
            "          WP       0.96      1.00      0.98        80\n",
            "         WRB       1.00      1.00      1.00        62\n",
            "\n",
            "    accuracy                           0.84     27156\n",
            "   macro avg       0.68      0.66      0.66     27156\n",
            "weighted avg       0.89      0.84      0.86     27156\n",
            "\n",
            "Correlation between class frequency and Precision in validation set: 0.3577762688973431\n",
            "\n",
            "Correlation between class frequency and Recall in validation set: 0.3111837305304964\n",
            "\n",
            "Correlation between class frequency and F1-score in validation set: 0.34335609751903395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the tensors and filter tokens as per your criteria\n",
        "y_val_flatten_tokens = [labels_vocabulary[int(token)] for token in y_val.flatten()\n",
        "                        if (int(token) != 0) & (int(token) in labels_vocabulary) & (labels_vocabulary[int(token)].isalnum())]\n",
        "y_test_flatten_tokens = [labels_vocabulary[int(token)] for token in y_test.flatten()\n",
        "                         if (int(token) != 0) & (int(token) in labels_vocabulary) & (labels_vocabulary[int(token)].isalnum())]\n",
        "y_train_flatten_tokens = [labels_vocabulary[int(token)] for token in y_train.flatten()\n",
        "                         if (int(token) != 0) & (int(token) in labels_vocabulary) & (labels_vocabulary[int(token)].isalnum())]\n",
        "\n",
        "# Count frequencies of each class in both y_val and y_test\n",
        "y_val_counts = Counter(y_val_flatten_tokens)\n",
        "y_test_counts = Counter(y_test_flatten_tokens)\n",
        "y_train_counts = Counter(y_train_flatten_tokens)\n",
        "\n",
        "\n",
        "# Extract labels and their corresponding counts\n",
        "labels = sorted(set(y_val_flatten_tokens + y_test_flatten_tokens + y_train_flatten_tokens))\n",
        "y_val_freq = [y_val_counts[label] for label in labels]\n",
        "y_test_freq = [y_test_counts[label] for label in labels]\n",
        "y_train_freq = [y_train_counts[label] for label in labels]\n",
        "\n",
        "# X locations for the groups\n",
        "index = np.arange(len(labels))\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(15, 6))\n",
        "bar_width = 0.35\n",
        "plt.bar(index - bar_width, y_train_freq, bar_width, color='orange', alpha=0.7, label='y_train')\n",
        "plt.bar(index, y_val_freq, bar_width, color='blue', alpha=0.7, label='y_val')\n",
        "plt.bar(index + bar_width, y_test_freq, bar_width, color='red', alpha=0.7, label='y_test')\n",
        "\n",
        "plt.xticks(index, labels, rotation='vertical')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Comparison of Class Frequencies in y_train, y_val, and y_test')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zP_ULX7r5Tmw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "2addc2ca-fcf8-439d-fa6d-2a82becc7539"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_errors(model: nn.Module, x: np.array, y:np.array, pad_token_idx: int = 0):\n",
        "    all_errors = []\n",
        "    total_predictions = 0\n",
        "\n",
        "    for idx in range(len(x)):\n",
        "        pred_pos_tags = infer(model, x[idx], device).cpu()\n",
        "        target_pos_tags: torch.Tensor = y[idx].cpu()\n",
        "\n",
        "        # Filter out padding\n",
        "        non_padding_mask = target_pos_tags != pad_token_idx\n",
        "        pred_pos_tags_no_padding = pred_pos_tags[non_padding_mask]\n",
        "        target_pos_tags_no_padding = target_pos_tags[non_padding_mask]\n",
        "\n",
        "        # Update total predictions\n",
        "        total_predictions += len(target_pos_tags_no_padding)\n",
        "\n",
        "        # Accumulate errors\n",
        "        for target_tag, pred_tag in zip(target_pos_tags_no_padding, pred_pos_tags_no_padding):\n",
        "            if target_tag != pred_tag:\n",
        "                all_errors.append((labels_vocabulary[target_tag.item()], labels_vocabulary[pred_tag.item()]))\n",
        "\n",
        "    return Counter(all_errors), total_predictions\n",
        "\n",
        "val_errors, val_total = analyze_errors(best_model, x_val, y_val)\n",
        "test_errors, test_total = analyze_errors(best_model, x_test, y_test)"
      ],
      "metadata": {
        "id": "WHRqBLKq9xyM"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_error_percentages(error_counts, total_predictions, num_common=10):\n",
        "    print(f\"\\nTop {num_common} Error Percentages:\")\n",
        "    for error, count in error_counts.most_common(num_common):\n",
        "        percentage = (count / total_predictions) * 100\n",
        "        print(f\"{error}: {percentage:.2f}%\")\n",
        "\n",
        "display_error_percentages(val_errors, val_total)\n",
        "display_error_percentages(test_errors, test_total)"
      ],
      "metadata": {
        "id": "zw7ehmUM9z-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b694c09-8f62-410b-aff4-bf051d93acc0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Error Percentages:\n",
            "('NN', 'VBN'): 1.29%\n",
            "('NNP', 'VBN'): 1.24%\n",
            "('NNS', 'VBN'): 1.16%\n",
            "('NNP', 'NN'): 0.98%\n",
            "('NN', 'JJ'): 0.68%\n",
            "('NNP', 'JJ'): 0.67%\n",
            "('JJ', 'VBN'): 0.61%\n",
            "('CD', 'VBN'): 0.52%\n",
            "('VBD', 'VBN'): 0.37%\n",
            "('VBG', 'VBN'): 0.36%\n",
            "\n",
            "Top 10 Error Percentages:\n",
            "('NNP', 'VBN'): 1.81%\n",
            "('NN', 'VBN'): 1.54%\n",
            "('NNS', 'VBN'): 0.92%\n",
            "('CD', 'VBN'): 0.86%\n",
            "('NN', 'JJ'): 0.86%\n",
            "('NNP', 'JJ'): 0.80%\n",
            "('NNP', 'NN'): 0.73%\n",
            "('JJ', 'VBN'): 0.52%\n",
            "('VBD', 'VBN'): 0.48%\n",
            "('CD', 'JJ'): 0.23%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_error_percentages(val_errors, val_total, test_errors, test_total, num_common=10):\n",
        "    print(f\"\\nComparison of Top {num_common} Errors (Validation vs Test):\")\n",
        "    common_errors = set([error for error, _ in val_errors.most_common(num_common)] +\n",
        "                        [error for error, _ in test_errors.most_common(num_common)])\n",
        "\n",
        "    for error in common_errors:\n",
        "        val_percentage = (val_errors[error] / val_total) * 100\n",
        "        test_percentage = (test_errors[error] / test_total) * 100\n",
        "        print(f\"{error} - Validation: {val_percentage:.2f}%, Test: {test_percentage:.2f}%\")\n",
        "\n",
        "compare_error_percentages(val_errors, val_total, test_errors, test_total)"
      ],
      "metadata": {
        "id": "pyeAzTb791A7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9abe7ae-9b81-4d6c-c4a3-aade3b1b8649"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison of Top 10 Errors (Validation vs Test):\n",
            "('VBD', 'VBN') - Validation: 0.37%, Test: 0.48%\n",
            "('VBG', 'VBN') - Validation: 0.36%, Test: 0.22%\n",
            "('NNP', 'NN') - Validation: 0.98%, Test: 0.73%\n",
            "('NN', 'VBN') - Validation: 1.29%, Test: 1.54%\n",
            "('NN', 'JJ') - Validation: 0.68%, Test: 0.86%\n",
            "('NNP', 'VBN') - Validation: 1.24%, Test: 1.81%\n",
            "('NNP', 'JJ') - Validation: 0.67%, Test: 0.80%\n",
            "('NNS', 'VBN') - Validation: 1.16%, Test: 0.92%\n",
            "('JJ', 'VBN') - Validation: 0.61%, Test: 0.52%\n",
            "('CD', 'VBN') - Validation: 0.52%, Test: 0.86%\n",
            "('CD', 'JJ') - Validation: 0.34%, Test: 0.23%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the reason for the higher f1-score on the test set compared to the one observed on the validation set?\n",
        "This can happen due to several reasons:\n",
        "1. Data Distribution Differences: If the validation and test sets are not sampled from the same distribution or if they have different characteristics, the model might perform differently on these sets. This is especially true if the test set is somehow easier for the model to predict, or more representative of the data the model was trained on.\n",
        "2. Overfitting to Validation Set: If you use the validation set extensively for hyperparameter tuning or model selection, there's a risk of overfitting to the validation set. This means the model is tuned specifically to perform well on the validation data, which might not generalize as well to the test set (or any unseen data).\n",
        "3. Size of the Datasets: If the validation set is much smaller than the test set, the evaluation on the validation set might be less reliable due to higher variance in the performance measure. This can lead to situations where the model appears to perform worse on the validation set simply due to the statistical noise inherent in a smaller sample size.\n",
        "4. Random Variation: Especially in cases where datasets are small, random variation can lead to differences in performance metrics. This is more pronounced in metrics like F1-score, which can be sensitive to the balance between precision and recall.\n",
        "5. Model Instability: If the model is highly sensitive to the input data (which can happen with complex models like deep neural networks), small differences in the data distribution between the validation and test sets can lead to significant differences in performance.\n",
        "6. Data Leakage: If there is some form of data leakage in the test set (but not in the validation set), the model might perform artificially well on the test set. Data leakage refers to a situation where information that should not be available during the training process inadvertently influences the model.\n",
        "It's important to ensure that both validation and test sets are representative of the real-world data the model is expected to encounter, and to be cautious about over-tuning models based on validation set performance. Regular checks for data consistency and distribution similarity can help mitigate some of these issues."
      ],
      "metadata": {
        "id": "aQRAGoueLAp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Error Analysis Report\n",
        "\n",
        "## Overview\n",
        "The analysis of the model's performance on the test and validation sets reveals insightful patterns and discrepancies in error rates. By focusing on the top 10 error percentages and their comparisons, we gain a clearer understanding of the model's strengths and weaknesses.\n",
        "\n",
        "## Common Error Patterns\n",
        "### Misclassification of Nouns (NN, NNP, NNS) as Verbs (VBN) and Adjectives (JJ):\n",
        "- This error type is prevalent in both sets, with NN to VBN being the most frequent error in validation and NNP to VBN in the test set.\n",
        "- The confusion between nouns and past participles (VBN) suggests a challenge in contextual understanding, especially in differentiating between nominalized verbs and their noun counterparts.\n",
        "\n",
        "### Misclassification of CD (Cardinal Numbers):\n",
        "- Notably, CD to VBN and CD to JJ are common errors, indicating difficulty in distinguishing numbers from verbs and adjectives.\n",
        "\n",
        "### Verb Confusions (VBG to VBN, VBD to VBN):\n",
        "- These errors suggest challenges in differentiating verb tenses and forms.\n",
        "\n",
        "## Correlation with Class Frequency\n",
        "The correlations between class frequency and performance metrics (precision, recall, F1-score) are relatively low. This suggests that class frequency is not a major determinant of these errors, pointing towards other factors such as contextual complexity or inherent model limitations.\n",
        "\n",
        "## Proposed Solutions\n",
        "### Contextual Enhancement:\n",
        "- Improve the model's understanding of context. Techniques like contextual embedding (e.g., BERT-based models) can be more effective in capturing the nuanced usage of words in different contexts.\n",
        "- Increasing the depth of the LSTM layers or experimenting with attention mechanisms might help the model capture more complex dependencies.\n",
        "\n",
        "### Data Augmentation:\n",
        "- Augmenting the training data with more examples of commonly confused pairs (like NN/VBN, CD/JJ) might help the model learn to distinguish these better.\n",
        "- Using synonym augmentation or back-translation could introduce more varied sentence structures, aiding in better generalization.\n",
        "\n",
        "### Class Imbalance Mitigation:\n",
        "- Address potential class imbalances, even though the correlation is low. Techniques such as oversampling rare classes or using class-weighted loss functions might be beneficial.\n",
        "\n",
        "### Error Analysis and Manual Review:\n",
        "- Conduct a thorough qualitative analysis of the errors. Manually reviewing misclassified instances can provide insights that are not evident from quantitative analysis alone.\n",
        "- Custom rules or post-processing steps could be introduced to handle specific, identifiable error patterns.\n",
        "\n",
        "### Model Experimentation:\n",
        "- Experiment with different model architectures (e.g., transformers, GRUs) or ensemble methods to see if they offer improved performance on these error types.\n",
        "\n",
        "### Hyperparameter Tuning:\n",
        "- Fine-tune hyperparameters such as learning rate, batch size, and dropout rates to optimize the model's performance.\n",
        "\n",
        "## Conclusion\n",
        "The model demonstrates a notable proficiency in tagging parts of speech but struggles with specific confusions, particularly in differentiating between nouns, verbs, and adjectives. Addressing these issues through a combination of data, model architecture, and contextual understanding enhancements could lead to significant improvements in the model's performance.\n"
      ],
      "metadata": {
        "id": "-vHzEjgtxGRe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOwnyCsslXWy"
      },
      "source": [
        "# [Task 7 - 1.0 points] Report\n",
        "\n",
        "Wrap up your experiment in a short report (up to 2 pages)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUgujR__lXWz"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Use the NLP course report template.\n",
        "* Summarize each task in the report following the provided template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlYwyuuqlXW0"
      },
      "source": [
        "### Recommendations\n",
        "\n",
        "The report is not a copy-paste of graphs, tables, and command outputs.\n",
        "\n",
        "* Summarize classification performance in Table format.\n",
        "* **Do not** report command outputs or screenshots.\n",
        "* Report learning curves to Figure format.\n",
        "* The error analysis section should summarize your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEcuGWVglXW2"
      },
      "source": [
        "# Submission\n",
        "\n",
        "* **Submit** your report in PDF format.\n",
        "* **Submit** your python notebook.\n",
        "* Make sure your notebook is **well organized**, with no temporary code, commented sections, tests, etc...\n",
        "* You can upload **model weights** in a cloud repository and report the link in the report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J55UYCbIlXW4"
      },
      "source": [
        "# FAQ\n",
        "\n",
        "Please check this frequently asked questions before contacting us"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWKGE6TulXW5"
      },
      "source": [
        "### Trainable Embeddings\n",
        "\n",
        "You are **free** to define a trainable or non-trainable Embedding layer to load the GloVe embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9fDx7hJlXW6"
      },
      "source": [
        "### Model architecture\n",
        "\n",
        "You **should not** change the architecture of a model (i.e., its layers).\n",
        "\n",
        "However, you are **free** to play with their hyperparameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwFc-m_SlXW7"
      },
      "source": [
        "### Neural Libraries\n",
        "\n",
        "You are **free** to use any library of your choice to implement the networks (e.g., Keras, Tensorflow, PyTorch, JAX, etc...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur3gbIN4lXW8"
      },
      "source": [
        "### Keras TimeDistributed Dense layer\n",
        "\n",
        "If you are using Keras, we recommend wrapping the final Dense layer with `TimeDistributed`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvHgGzmblXW9"
      },
      "source": [
        "### Error Analysis\n",
        "\n",
        "Some topics for discussion include:\n",
        "   * Model performance on most/less frequent classes.\n",
        "   * Precision/Recall curves.\n",
        "   * Confusion matrices.\n",
        "   * Specific misclassified samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vsd3AEcmlXW-"
      },
      "source": [
        "### Punctuation\n",
        "\n",
        "**Do not** remove punctuation from documents since it may be helpful to the model.\n",
        "\n",
        "You should **ignore** it during metrics computation.\n",
        "\n",
        "If you are curious, you can run additional experiments to verify the impact of removing punctuation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOSO5ofLlXXA"
      },
      "source": [
        "# The End"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "prometeia",
      "language": "python",
      "display_name": "prometeia"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}